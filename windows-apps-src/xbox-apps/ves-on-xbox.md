---
title: Оболочка с поддержкой голоса (VE) в Xbox
description: Узнайте, как добавить поддержку управления голосовыми сообщениями в приложения UWP на Xbox.
ms.date: 10/19/2017
ms.topic: article
keywords: Windows 10, UWP, Xbox, речь, оболочка с поддержкой голоса
ms.openlocfilehash: f51ec2c93a904893dc337545f634d04affde10fd
ms.sourcegitcommit: 26bb75084b9d2d2b4a76d4aa131066e8da716679
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/06/2020
ms.locfileid: "75685181"
---
# <a name="using-speech-to-invoke-ui-elements"></a>Использование речи для вызова элементов пользовательского интерфейса

Оболочка с поддержкой голоса (VE) — это расширение для платформы Windows Speech, которое обеспечивает поддержку распознавания речи первого класса в приложениях, позволяя пользователям использовать речь для вызова элементов управления на экране и вставки текста с помощью диктовки. VE стремится предоставить общий комплексный ИТ-опыт на всех оболочках и устройствах Windows с минимальными усилиями, необходимыми разработчикам приложений.  Для этого он использует платформу Microsoft Speech Platform и платформу автоматизации пользовательского интерфейса (UIA).

## <a name="user-experience-walkthrough"></a>Пошаговое руководство по работе с пользователем ##
Ниже приведен обзор того, что может произойти при использовании VE на Xbox, и он должен помочь установить контекст, прежде чем углубляться в сведения о том, как работает VE.

- Пользователь включает консоль Xbox и хочет просмотреть свои приложения, чтобы найти нечто интересующее:

        User: "Hey Cortana, open My Games and Apps"

- Пользователь остается в активном режиме прослушивания (ALM). Это означает, что консоль теперь ожидает от пользователя вызова элемента управления, видимого на экране, без необходимости говорить, что Кортана — каждый раз.  Теперь пользователь может переключиться на просмотр приложений и прокрутить список приложений:

        User: "applications"

- Чтобы прокрутить представление, пользователь может просто сказать:

        User: "scroll down"

- Пользователь видит графическую рамку приложения, которым они интересуют, но забыли имя.  Пользователь запрашивает отображение меток речевого Совета:

        User: "show labels"

- Теперь, когда ясно, что сказать, приложение можно запустить:

        User: "movies and TV"

- Чтобы выйти из режима активного прослушивания, пользователь сообщает Xbox о необходимости прекратить прослушивание:

        User: "stop listening"

- Позже можно запустить новый активный сеанс прослушивания:

        User: "Hey Cortana, make a selection" or "Hey Cortana, select"

## <a name="ui-automation-dependency"></a>Зависимость модели автоматизации пользовательского интерфейса ##
VE — это клиент автоматизации пользовательского интерфейса, который зависит от информации, предоставляемой приложением с помощью поставщиков автоматизации пользовательского интерфейса. Это та же инфраструктура, которая уже используется функцией экранного диктора на платформах Windows.  Модель автоматизации пользовательского интерфейса обеспечивает программный доступ к элементам пользовательского интерфейса, включая имя элемента управления, его тип и шаблоны элементов управления, которые он реализует.  По мере изменения пользовательского интерфейса в приложении VE будет реагировать на события обновления UIA и повторно выполнить синтаксический анализ обновленного дерева модели автоматизации пользовательского интерфейса, чтобы найти все элементы, которые можно подбирать, используя эти сведения для создания грамматики распознавания речи. 

Все приложения UWP имеют доступ к платформе автоматизации пользовательского интерфейса и могут предоставлять сведения о пользовательском интерфейсе независимо от того, на какой графической платформе они созданы (XAML, DirectX, Direct3D, Xamarin и т. д.).  В некоторых случаях, как и в XAML, большая часть тяжелой работы выполняется платформой, что значительно сокращает объем работ, необходимых для поддержки экранного диктора и VE.

Дополнительные сведения об автоматизации пользовательского интерфейса см. в статье [основы автоматизации пользовательского интерфейса](https://msdn.microsoft.com/library/ms753107(v=vs.110).aspx "Основы модели автоматизации пользовательского интерфейса").

## <a name="control-invocation-name"></a>Имя вызова элемента управления ##
VE использует следующий эвристический метод для определения фразы, регистрируемой с помощью распознавателя речи, в качестве имени элемента управления (IE. что нужно сказать пользователю для вызова элемента управления).  Это также фраза, которая будет отображаться в метке голосового Совета.

Источник имени в порядке приоритета:

1. Если элемент имеет `LabeledBy` присоединенное свойство, VE будет использовать `AutomationProperties.Name` этой текстовой метки.
2. `AutomationProperties.Name` элемента.  В XAML текстовое содержимое элемента управления будет использоваться в качестве значения по умолчанию для `AutomationProperties.Name`.
3. Если элемент управления является ListItem или Button, VE будет искать первый дочерний элемент с допустимым `AutomationProperties.Name`.

## <a name="actionable-controls"></a>Элементы управления, подопределяющие действия ##
VE считает элемент управления пригодным для действий, если он реализует один из следующих шаблонов элементов управления автоматизации:

- **InvokePattern** (например, (Кнопка)) — представляет элементы управления, которые инициируют или выполняют одно однозначное действие и не сохраняют состояние при активации.

- **Тогглепаттерн** (например, (Флажок)) — представляет элемент управления, который может циклически проходить через набор состояний и поддерживать состояние после установки.

- **Селектионитемпаттерн** (например, Поле со списком) — представляет элемент управления, который выступает в качестве контейнера для коллекции выбираемых дочерних элементов.

- **ExpandCollapsePattern** (например, Поле со списком) — представляет элементы управления, которые визуально разворачиваются для отображения содержимого и сворачиваются для скрытия содержимого.

- **ScrollPattern** (например, Список) — представляет элементы управления, которые выступают в качестве прокручиваемых контейнеров для коллекции дочерних элементов.

## <a name="scrollable-containers"></a>Прокручиваемые контейнеры ##
Для прокручиваемых контейнеров, поддерживающих ScrollPattern, VE будет прослушивать голосовые команды, такие как "Прокрутка влево", "Прокрутка вправо" и т. д., и вызовет прокрутку с соответствующими параметрами, когда пользователь запускает одну из этих команд.  Команды прокрутки вставляются на основе значения свойств `HorizontalScrollPercent` и `VerticalScrollPercent`.  Например, если `HorizontalScrollPercent` больше 0, будет добавлено значение "Прокрутка влево", если оно меньше 100, будет добавлено "Прокрутка вправо" и т. д.

## <a name="narrator-overlap"></a>Перекрытие экранного диктора ##
Приложение "Экранный диктор" также является клиентом автоматизации пользовательского интерфейса и использует свойство `AutomationProperties.Name` как один из источников для текста, который он считывает для выбранного в данный момент элемента пользовательского интерфейса.  Чтобы обеспечить лучшую доступность, многие разработчики приложений применяют перегрузку свойства `Name` с длинным описательным текстом с целью предоставления дополнительных сведений и контекста при чтении экранного диктора.  Однако это приводит к конфликту между двумя компонентами: VE требует короткие фразы, которые соответствуют или точно соответствуют видимому тексту элемента управления, а преимущества экранного диктора — больше, чем более описательные фразы для предоставления лучшего контекста.

Чтобы устранить эту проблему, начиная с обновления Windows 10 Creators, Экранный диктор был обновлен для просмотра свойства `AutomationProperties.HelpText`.  Если это свойство не пусто, Экранный диктор будет обращаться к его содержимому в дополнение к `AutomationProperties.Name`.  Если `HelpText` пустой, программа экранного диктора будет считать только содержимое имени.  Это позволяет использовать более длинные описательные строки, когда это необходимо, но в свойстве `Name` сохраняется более короткая удобная фраза для распознавания речи.

![](images/ves_narrator.jpg)

Дополнительные сведения см. [в разделе Свойства автоматизации для поддержки специальных возможностей в пользовательском интерфейсе](https://msdn.microsoft.com/library/ff400332(vs.95).aspx "Свойства автоматизации для поддержки специальных возможностей в пользовательском интерфейсе").

## <a name="active-listening-mode-alm"></a>Активный режим прослушивания (ALM) ##
### <a name="entering-alm"></a>Вход в ALM ###
В Xbox ve не ожидает постоянного ввода речи.  Пользователю необходимо явно перейти в режим активного прослушивания:

- "Привет, Кортана, Select" или
- "Привет, Кортана, сделать выбор"

Существует несколько других команд Кортаны, которые также оставляют пользователя в активном прослушивании по завершении, например: "Привет, Кортана, вход" или "Привет, Кортана!". 

Ввод ALM приведет к следующему результату:

- Наложение Кортаны будет отображаться в правом верхнем углу, что говорит пользователю, что он может сказать, что они видят.  В то время как пользователь говорит, фрагменты фраз, распознаваемые распознавателем речи, также будут показаны в этом расположении.
- VE анализирует дерево UIA, находит все элементы управления с поддержкой действий, регистрирует свой текст в грамматике распознавания речи и запускает непрерывный сеанс прослушивания.

    ![](images/ves_overlay.png)

### <a name="exiting-alm"></a>Выход из ALM ###
Система будет оставаться в ALM, пока пользователь взаимодействует с ИНТЕРФЕЙСом пользователя с помощью голоса.  Существует два способа выхода из ALM:

- Пользователь явно говорит: "прерывать прослушивание" или
- Если в течение 17 секунд после входа в ALM или с момента последнего положительного распознавания не было положительного распознавания, произойдет тайм-аут.

## <a name="invoking-controls"></a>Вызов элементов управления ##
Когда в ALM пользователь может взаимодействовать с пользовательским ИНТЕРФЕЙСом с помощью голоса.  Если пользовательский интерфейс настроен правильно (свойства имени, соответствующие отображаемому тексту), использование голоса для выполнения действий должно быть простым и естественным интерфейсом.  Пользователь должен иметь возможность просто сказать, что они видят на экране.

## <a name="overlay-ui-on-xbox"></a>Наложение пользовательского интерфейса на Xbox ##
Имя VE, наследуемое для элемента управления, может отличаться от фактического видимого текста в пользовательском интерфейсе.  Это может быть вызвано свойством `Name` элемента управления или присоединенным `LabeledBy`ным элементом, явно заданным для другой строки.  Или элемент управления не имеет текста графического пользовательского интерфейса, но только значка или изображения.

В таких случаях пользователям требуется способ увидеть, что необходимо сказать для вызова такого элемента управления.  Таким образом, один раз в активном ожидании можно отобразить подсказки, выполнив слово "Показать метки".  Это приводит к тому, что метки речевого Совета будут отображаться поверх каждого элемента управления, с которым возможно действие.

Существует ограничение в 100 меток, поэтому, если в пользовательском интерфейсе приложения больше элементов управления, подставляемых для действия, чем 100, будут отображаться не все метки.  Метки, выбираемые в этом случае, не являются детерминированными, так как они зависят от структуры и композиции текущего пользовательского интерфейса, которые сначала перечисляются в дереве UIA.

После отображения меток речевого Совета команда для ее скрытия остается видимой, пока не произойдет одно из следующих событий:

- пользователь вызывает элемент управления
- пользователь переходит за пределы текущей сцены
- пользователь говорит: "прерывать прослушивание"
- время ожидания активного режима прослушивания истекло

## <a name="location-of-voice-tip-labels"></a>Расположение меток речевого Совета ##
Метки речевого Совета располагаются горизонтально и вертикально в центре элемента управления Баундингректангле.  Если элементы управления небольшие и тесно сгруппированы, то метки могут перекрываться или становиться невидимыми для других пользователей, и VE попытается отложить эти метки друг от друга, чтобы они были видны.  Однако это не гарантирует работу в 100% времени.  При наличии очень переполненного пользовательского интерфейса, скорее всего, некоторые метки будут скрыты другими. Проверьте пользовательский интерфейс с помощью "Показывать метки", чтобы убедиться в наличии достаточного места для видимости голоса.

![](images/ves_labels.png)

## <a name="combo-boxes"></a>Поля со списком ##
Когда поле со списком разворачивается, каждый отдельный элемент в поле со списком получает свой собственный текст Совета по голосовым советам, и часто они появятся поверх существующих элементов управления, расположенных за раскрывающимся списком.  Во избежание ненужных и путаницных муддле меток (когда метки элементов поля со списком пересекаются с метками элементов управления, находящимся за полем со списком), когда поле со списком разворачивается, будут показаны только метки для его дочерних элементов.  все остальные метки голоса будут скрыты.  Затем пользователь может либо выбрать один из раскрывающихся элементов, либо закрыть поле со списком.

- Метки в свернутых полях со списком:

    ![](images/ves_combo_closed.png)

- Метки в развернутом поле со списком:

    ![](images/ves_combo_open.png)


## <a name="scrollable-controls"></a>Прокручиваемые элементы управления ##
Для прокручиваемых элементов управления всплывающие подсказки для команд прокрутки будут центрированы по всем краям элемента управления.  Советы по голосовому использованию будут отображаться только для тех направлений прокрутки, которые являются подставляемыми. Например, если вертикальная прокрутка недоступна, прокрутка вверх и прокрутка вниз не будет отображаться.  Если имеется несколько прокручиваемых регионов, VE будет использовать порядковые номера для различения между ними (например, "Прокрутка вправо 1", "Прокрутка вправо 2" и т. д.).

![](images/ves_scroll.png) 

## <a name="disambiguation"></a>Уточнение ##
Если несколько элементов пользовательского интерфейса имеют одно и то же имя или распознаватель речи сопоставляется с несколькими кандидатами, VE будет переходить в режим неоднозначности.  В этом режиме будут отображаться метки голоса TIP для элементов, чтобы пользователь мог выбрать нужное. Пользователь может отменить режим неоднозначности, указав "Отмена".

Пример

- В активном режиме прослушивания перед устранением неоднозначности; пользователь говорит: «AM I неоднозначен».

    ![](images/ves_disambig1.png) 

- Обе кнопки совпадают; Устранение неоднозначности запущено:

    ![](images/ves_disambig2.png) 

- Отображается действие щелчка, если выбран вариант "Select 2":

    ![](images/ves_disambig3.png) 
 
## <a name="sample-ui"></a>Пример пользовательского интерфейса ##
Ниже приведен пример пользовательского интерфейса на основе XAML, который задает AutomationProperties.Name различными способами.

    <Page
        x:Class="VESSampleCSharp.MainPage"
        xmlns="http://schemas.microsoft.com/winfx/2006/xaml/presentation"
        xmlns:x="http://schemas.microsoft.com/winfx/2006/xaml"
        xmlns:local="using:VESSampleCSharp"
        xmlns:d="http://schemas.microsoft.com/expression/blend/2008"
        xmlns:mc="http://schemas.openxmlformats.org/markup-compatibility/2006"
        mc:Ignorable="d">
        <Grid Background="{ThemeResource ApplicationPageBackgroundThemeBrush}">
            <Button x:Name="button1" Content="Hello World" HorizontalAlignment="Left" Margin="44,56,0,0" VerticalAlignment="Top"/>
            <Button x:Name="button2" AutomationProperties.Name="Launch Game" Content="Launch" HorizontalAlignment="Left" Margin="44,106,0,0" VerticalAlignment="Top" Width="99"/>
            <TextBlock AutomationProperties.Name="Day of Week" x:Name="label1" HorizontalAlignment="Left" Height="22" Margin="168,62,0,0" TextWrapping="Wrap" Text="Select Day of Week:" VerticalAlignment="Top" Width="137"/>
            <ComboBox AutomationProperties.LabeledBy="{Binding ElementName=label1}" x:Name="comboBox" HorizontalAlignment="Left" Margin="310,57,0,0" VerticalAlignment="Top" Width="120">
                <ComboBoxItem Content="Monday" IsSelected="True"/>
                <ComboBoxItem Content="Tuesday"/>
                <ComboBoxItem Content="Wednesday"/>
                <ComboBoxItem Content="Thursday"/>
                <ComboBoxItem Content="Friday"/>
                <ComboBoxItem Content="Saturday"/>
                <ComboBoxItem Content="Sunday"/>
            </ComboBox>
            <Button x:Name="button3" HorizontalAlignment="Left" Margin="44,156,0,0" VerticalAlignment="Top" Width="213">
                <Grid>
                    <TextBlock AutomationProperties.Name="Accept">Accept Offer</TextBlock>
                    <TextBlock Margin="0,25,0,0" Foreground="#FF5A5A5A">Exclusive offer just for you</TextBlock>
                </Grid>
            </Button>
        </Grid>
    </Page>


Использование приведенного выше примера демонстрирует, как пользовательский интерфейс будет выглядеть с метками голоса и без них.
 
- В активном режиме прослушивания без меток отображаются:

    ![](images/ves_alm_nolabels.png) 

- В активном режиме прослушивания после того, как пользователь выводит сообщение "Показывать метки":

    ![](images/ves_alm_labels.png) 

В случае `button1`XAML автоматически заполняет свойство `AutomationProperties.Name`, используя текст из видимого текстового содержимого элемента управления.  Именно поэтому существует метка голоса TIP, несмотря на то, что не существует явно заданного `AutomationProperties.Name`.

При использовании `button2`мы явно задали для `AutomationProperties.Name` значение, отличное от текста элемента управления.

В `comboBox`мы использовали свойство `LabeledBy`, чтобы ссылаться на `label1` в качестве источника `Name`автоматизации, а в `label1` мы задали более естественную фразу, чем отрисовка на экране ("день недели", а не "Выбор дня недели").

Наконец, при использовании `button3`VE извлекает `Name` из первого дочернего элемента, так как сам `button3` не имеет набора `AutomationProperties.Name`.

## <a name="see-also"></a>См. также статью
- [Основы модели автоматизации пользовательского интерфейса](https://msdn.microsoft.com/library/ms753107(v=vs.110).aspx "Основы модели автоматизации пользовательского интерфейса")
- [Свойства автоматизации для поддержки специальных возможностей в пользовательском интерфейсе](https://msdn.microsoft.com/library/ff400332(vs.95).aspx "Свойства автоматизации для поддержки специальных возможностей в пользовательском интерфейсе")
- [Вопросы и ответы](frequently-asked-questions.md)
- [Приложения UWP для Xbox One](index.md)
